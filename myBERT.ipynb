{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### myBERT   \n",
    "Create and train my own BERT language model.  \n",
    "Article: https://www.kdnuggets.com/2021/08/train-bert-model-scratch.html?utm_source=pocket_mylist    \n",
    "Christoph Windheuser    \n",
    "August 19, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import AdamW\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset oscar (/home/christoph/.cache/huggingface/datasets/oscar/unshuffled_deduplicated_it/1.0.0/84838bd49d2295f62008383b05620571535451d84545037bb94d6f3501651df2)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('oscar', 'unshuffled_deduplicated_it')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text'],\n",
       "        num_rows: 28522082\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text'],\n",
       "    num_rows: 28522082\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='int64', id=None), 'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': \"La estrazione numero 48 del 10 e LOTTO ogni 5 minuti e' avvenuta sabato 15 settembre 2018 alle ore 04:00 a Roma, nel Centro Elaborazione Dati della Lottomatica Italia (ora GTech SpA), con la supervisione della Amministrazione Autonoma dei Monopoli di Stato (AAMS), incaricata di vigilare sulla regolarità delle operazioni di sorteggio.\\nIl Montepremi della 48ª estrazione viene ripartito tra i vincitori delle singole categorie di premio.\\nRicorda di controllare il Numero ORO 53. E, se lo hai giocato, anche il DOPPIO ORO 53 e 66. Se indovini puoi vincere premi più ricchi.\\nIl nostro sito web impiega cookies per migliorare la navigazione del visitatore. L’utente è consapevole che, continuando a visitare il nostro sito web, accetta l’utilizzo dei cookies Accetto Informazioni\\n(C) Copyright 2013-2017 10elotto.biz | Il presente sito è da considerarsi un sito indipendente, NON collegato alla rete ufficiale Gtech SpA.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write about 2852 text_<#>.txt files with 10.000 samples each. (# = 0 until 2852)\n",
    "# Only do it onece!\n",
    "\n",
    "# text_data  = []\n",
    "# file_count = 0\n",
    "\n",
    "# !pwd\n",
    "\n",
    "# for sample in tqdm(dataset['train']):\n",
    "#    sample = sample['text'].replace('\\n', '')\n",
    "#    text_data.append(sample)\n",
    "#    if len(text_data) == 10_000:\n",
    "\n",
    "# once we git the 10K mark, save to file\n",
    "\n",
    "#        with open(f'data/text/oscar_it/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "#            fp.write('\\n'.join(text_data))\n",
    "#        text_data = []\n",
    "#        file_count += 1\n",
    "\n",
    "# after saving in 10K chunks, we will have ~2082 leftover samples, we save those now too\n",
    "# with open(f'data/text/oscar_it/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "#     fp.write('\\n'.join(text_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [str(x) for x in Path('data/text/oscar_it').glob('**/*.txt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/text/oscar_it/text_1732.txt',\n",
       " 'data/text/oscar_it/text_1927.txt',\n",
       " 'data/text/oscar_it/text_2374.txt',\n",
       " 'data/text/oscar_it/text_469.txt',\n",
       " 'data/text/oscar_it/text_2340.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=paths[:5], vocab_size=30_522, min_frequency=2,\n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filiberto/vocab.json', 'filiberto/merges.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tokenizer model at ./filiberto\n",
    "\n",
    "# os.mkdir('./filiberto')\n",
    "tokenizer.save_model('filiberto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tokenizer using the tokenizer we initialized and saved to file\n",
    "tokenizer = RobertaTokenizer.from_pretrained('filiberto', max_len=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our tokenizer on a simple sentence\n",
    "tokens = tokenizer('ciao, come va?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 15253, 16, 478, 589, 35, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 15253, 16, 478, 589, 35, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM Training Input Pipeline (MLM = Masked Language Modeling)    \n",
    "youTube Video: https://www.youtube.com/watch?v=heTYbpr9mD8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Language Model\n",
    "# return a attention mask vector for training, mask ID = 4\n",
    "\n",
    "def mlm(tensor):\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    mask_arr = (rand < 0.15) * (tensor > 2)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        tensor[i, selection] = 4\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/text/oscar_it/text_1732.txt',\n",
       " 'data/text/oscar_it/text_1927.txt',\n",
       " 'data/text/oscar_it/text_2374.txt',\n",
       " 'data/text/oscar_it/text_469.txt',\n",
       " 'data/text/oscar_it/text_2340.txt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [str(x) for x in Path('data/text/oscar_it').glob('**/*.txt')]\n",
    "paths[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b864d525ed74c8eaaf0074375f6fc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# one iteration path takes 55 seconds\n",
    "\n",
    "input_ids = []\n",
    "mask      = []\n",
    "labels    = []\n",
    "\n",
    "for path in tqdm(paths[:50]):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    sample = tokenizer(lines, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    labels.append(sample.input_ids)\n",
    "    mask.append(sample.attention_mask)\n",
    "    input_ids.append(mlm(sample.input_ids.detach().clone()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save objects as pickle files\n",
    "#\n",
    "\n",
    "f_input_ids = open(\"input_ids.pkl\", \"wb\")\n",
    "pickle.dump(input_ids, f_input_ids)\n",
    "f_input_ids.close()\n",
    "\n",
    "f_mask = open(\"mask.pkl\", \"wb\")\n",
    "pickle.dump(mask, f_mask)\n",
    "f_mask.close()\n",
    "\n",
    "f_labels = open(\"labels.pkl\", \"wb\")\n",
    "pickle.dump(labels, f_labels)\n",
    "f_labels.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load objects back from the pickle files\n",
    "# The notebook can be started at this point\n",
    "\n",
    "f_input_ids = open(\"input_ids.pkl\", \"rb\")\n",
    "input_ids   = pickle.load(f_input_ids)\n",
    "f_input_ids.close()\n",
    "\n",
    "f_mask = open(\"mask.pkl\", \"rb\")\n",
    "mask   = pickle.load(f_mask)\n",
    "f_mask.close()\n",
    "\n",
    "f_labels = open(\"labels.pkl\", \"rb\")\n",
    "labels   = pickle.load(f_labels)\n",
    "f_labels.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    0,    37,    42,  ...,     1,     1,     1],\n",
       "         [    0,  2938,   707,  ...,     1,     1,     1],\n",
       "         [    0, 28423,   290,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  1414,  6342,  ...,  1227,     4,     2],\n",
       "         [    0,    37, 18027,  ...,     4,     4,     2],\n",
       "         [    0,  1414,  3790,  ...,     1,     1,     1]]),\n",
       " tensor([[    0,    12, 21935,  ...,     1,     1,     1],\n",
       "         [    0,     4,   956,  ...,     1,     1,     1],\n",
       "         [    0,    48,   324,  ...,   452, 19806,     2],\n",
       "         ...,\n",
       "         [    0,  2314,    18,  ...,     1,     1,     1],\n",
       "         [    0,    52,   520,  ...,     1,     1,     1],\n",
       "         [    0,  1596,  5261,  ...,     1,     1,     1]])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " # torch.cat(input_ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids)\n",
    "mask      = torch.cat(mask)\n",
    "labels    = torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  2938,   707,   339,   324,  7958,  8426,     4, 16614,   376])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  2938,   707,   339,   324,  7958,  8426,   343, 16614,   376])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': mask,\n",
    "    'labels': labels\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "# this caused an Cuda Out-of-Memory Error!\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig(\n",
    "    vocab_size=tokenizer.vocab_size,       # vocab_size = 30_522\n",
    "    max_position_embeddings=514,           # = max_length + 2 (for special tokens)\n",
    "    hidden_size=768, \n",
    "    num_attention_heads=12,\n",
    "#    num_hidden_layers=6,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move our model over to the selected device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bdffb8b48e47cfbcb0b64b2728f32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        \n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # pull all tensor batches required for training\n",
    "        input_ids      = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels         = batch['labels'].to(device)\n",
    "    \n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=_attention_mask, labels=labels)\n",
    "        loss    = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "        loop.set_description(f'Epoch: {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./filiberto')  # and don't forget to save filiBERTo!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at filiberto and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fill = pipeline('fill-mask', model='filiberto', tokenizer='filiberto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'ciao? va?',\n",
       "  'score': 0.13754770159721375,\n",
       "  'token': 35,\n",
       "  'token_str': '?'},\n",
       " {'sequence': \"ciao' va?\",\n",
       "  'score': 0.012243658304214478,\n",
       "  'token': 11,\n",
       "  'token_str': \"'\"},\n",
       " {'sequence': 'ciao che va?',\n",
       "  'score': 0.010065736249089241,\n",
       "  'token': 313,\n",
       "  'token_str': ' che'},\n",
       " {'sequence': 'ciao una va?',\n",
       "  'score': 0.009317081421613693,\n",
       "  'token': 376,\n",
       "  'token_str': ' una'},\n",
       " {'sequence': 'ciao la va?',\n",
       "  'score': 0.009047871455550194,\n",
       "  'token': 306,\n",
       "  'token_str': ' la'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill(f'ciao {fill.tokenizer.mask_token} va?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'buongiorno,? va?',\n",
       "  'score': 0.10432537645101547,\n",
       "  'token': 35,\n",
       "  'token_str': '?'},\n",
       " {'sequence': 'buongiorno,, va?',\n",
       "  'score': 0.07070033252239227,\n",
       "  'token': 16,\n",
       "  'token_str': ','},\n",
       " {'sequence': 'buongiorno, che va?',\n",
       "  'score': 0.016522590070962906,\n",
       "  'token': 313,\n",
       "  'token_str': ' che'},\n",
       " {'sequence': 'buongiorno, la va?',\n",
       "  'score': 0.012377028353512287,\n",
       "  'token': 306,\n",
       "  'token_str': ' la'},\n",
       " {'sequence': 'buongiorno, di va?',\n",
       "  'score': 0.011870961636304855,\n",
       "  'token': 275,\n",
       "  'token_str': ' di'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill(f'buongiorno, {fill.tokenizer.mask_token} va?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
